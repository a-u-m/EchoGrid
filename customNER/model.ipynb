{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7dqWS4VozD-9"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "db = DocBin() # create a DocBin object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ofwgj4eTIwT"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--aCr9ZazlVG",
        "outputId": "77011870-44b4-45cd-92da-dc5860f82a6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-09-18 12:48:15.439663: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.6.0/en_core_web_lg-3.6.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-lg==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYOlOX_QFI9u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "f1 = open('typeA_B_train_dataset.json')\n",
        "f2 = open('typeA_B_test_dataset.json')\n",
        "\n",
        "TRAIN_DATA = json.load(f1)\n",
        "TEST_DATA = json.load(f2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj6L8jyRFCW-",
        "outputId": "d3a0653d-c689-4967-929e-7c6fd5374bb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 92/92 [00:00<00:00, 4543.83it/s]\n"
          ]
        }
      ],
      "source": [
        "for text, annot in tqdm(TRAIN_DATA['annotations']):\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "        span = doc.char_span(start,end,label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents\n",
        "    db.add(doc)\n",
        "db.to_disk(\"./typeA_B_train_dataset.spacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfIpTmCZFCKo",
        "outputId": "0e6f42f8-3086-47fc-f942-e99f398e605e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:00<00:00, 3014.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for text, annot in tqdm(TEST_DATA['annotations']):\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in annot[\"entities\"]:\n",
        "        span = doc.char_span(start,end,label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    doc.ents = ents\n",
        "    db.add(doc)\n",
        "db.to_disk(\"./typeA_B_test_dataset.spacy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fy8m5Srza1n",
        "outputId": "f8e7c77e-3b7f-45b0-f72c-e467375f6e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-09-20 10:45:53.747630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     69.17   19.39   14.80   28.14    0.19\n",
            " 36     200          1.83    886.85   99.66   99.33  100.00    1.00\n",
            " 80     400          0.00      0.00   99.66   99.33  100.00    1.00\n",
            "131     600          0.00      0.00   99.66   99.33  100.00    1.00\n",
            "198     800          0.00      0.00   99.66   99.33  100.00    1.00\n",
            "273    1000          0.00      0.00   99.66   99.33  100.00    1.00\n",
            "373    1200          0.00      0.00   99.66   99.33  100.00    1.00\n",
            "473    1400          0.00      0.00   99.66   99.33  100.00    1.00\n",
            "596    1600          0.00      0.00   99.66   99.33  100.00    1.00\n",
            "796    1800          0.00      0.00   99.66   99.33  100.00    1.00\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train config.cfg --output ./ --paths.train ./typeA_B_train_dataset.spacy --paths.dev ./typeA_B_test_dataset.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X3hBkwLaH_k",
        "outputId": "3f13040e-1fe7-46e5-c023-27fed00bdf4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2ad4mgqcsQ5"
      },
      "outputs": [],
      "source": [
        "nlp_ner = spacy.load(\"/content/model-best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXSh53yznsq3"
      },
      "outputs": [],
      "source": [
        "!ls /content/gdrive/MyDrive/Saved\\ Models/typeA_model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzIkKpxmnpnV"
      },
      "outputs": [],
      "source": [
        "nlp_ner.to_disk(\"/content/gdrive/MyDrive/Saved\\ Models/typeA_model/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEDAxEp2npci"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "fHpCNVoN4a46",
        "outputId": "a6323749-20d3-4b7d-b539-bd7a4b4cae90"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6f4918babc06>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming 'nlp_ner' is custom-trained spaCy NER model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp_ner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ensure that Product Inventory is typed in G2\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Process the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Iterate through named entities and filter by label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nlp_ner' is not defined"
          ]
        }
      ],
      "source": [
        "values = []\n",
        "cells = []\n",
        "type =[]\n",
        "\n",
        "# Assuming 'nlp_ner' is custom-trained spaCy NER model\n",
        "doc = nlp_ner(\"Ensure that Product Inventory is typed in G2\")  # Process the text\n",
        "\n",
        "# Iterate through named entities and filter by label\n",
        "print(doc.ents)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ == \"VALUE\":\n",
        "        values.append(ent.text)\n",
        "    elif (ent.label_ == \"TYPE A\" or ent.label_ == \"TYPE B\" or ent.label_ == \"TYPE C\"):\n",
        "        type.append(ent.label_)\n",
        "    elif ent.label_ == \"CELL\":\n",
        "        cells.append(ent.text)\n",
        "\n",
        "print(\"Extracted Type:\",type)\n",
        "print(\"Extracted Values:\", values)\n",
        "print(\"Extracted Cells:\", cells)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mOglqDugZ0A",
        "outputId": "40298da9-afd4-435c-e3ac-51b94adad4d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INSERT E8 Customer Feedback\n"
          ]
        }
      ],
      "source": [
        "# Concatation trial\n",
        "\n",
        "cmd = \"Insert \" + str(cells[0]) + \" \"+ str(values[0])\n",
        "\n",
        "print(cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFYr8s7tfyRp",
        "outputId": "514d4ae4-2cee-45eb-94d3-94913b610f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TYPE A\n",
            "Insert C7 Monthly Expenses\n"
          ]
        }
      ],
      "source": [
        "# code to create the final instruction for the Google Sheet API\n",
        "\n",
        "\n",
        "for t in type:\n",
        "  print(t)\n",
        "  if t==\"TYPE A\":\n",
        "    # the sentence is of INSERT\n",
        "\n",
        "    cmd = \"Insert \" + str(cells[0]) + \" \"+ str(values[0])\n",
        "    print(cmd)\n",
        "  elif t==\"TYPE B\":\n",
        "    # the sentence is of type delete\n",
        "    cmd = \"Delete \" + str(cells[0])\n",
        "    print(cmd)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOD0Szjem9Uz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}